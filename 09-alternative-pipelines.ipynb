{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import subprocess\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "def load_train_data(split=True):\n",
    "    target = \"Survived\"\n",
    "    data = pd.read_csv(\"./train.csv\", index_col=\"PassengerId\")\n",
    "    print(\"load_train_data: done\")\n",
    "    \n",
    "    if split:\n",
    "        return split_features_target(data, target)\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "def split_features_target(df, target=\"Survived\"):\n",
    "    features = [column for column in df.columns if not column == target]\n",
    "    return df[features], df[target]\n",
    "\n",
    "def load_x_test():\n",
    "    return pd.read_csv(\"./test.csv\", index_col=\"PassengerId\")\n",
    "    \n",
    "# Save Kaggle submission file\n",
    "def submission_df(y_pred):\n",
    "    X_test = load_x_test()\n",
    "    return pd.DataFrame(y_pred, index=X_test.index, columns=[\"Survived\"])\n",
    "\n",
    "def save_submission_file(y_pred, filename):\n",
    "    df = submission_df(y_pred)\n",
    "    path = \"./\" + filename\n",
    "\n",
    "    try:\n",
    "        df.to_csv(path)\n",
    "    except Exception:\n",
    "        print(\"Couldnâ€™t save submission.\")\n",
    "    else:\n",
    "        print(\"Submission saved.\")\n",
    "        \n",
    "# Submit score to Kaggle\n",
    "def submit_predictions(y_pred, filename, message):\n",
    "    save_submission_file(y_pred, filename)\n",
    "\n",
    "    completed_process = subprocess.run(\n",
    "        [\n",
    "            \"kaggle\",\n",
    "            \"competitions\",\n",
    "            \"submit\",\n",
    "            \"-c\",\n",
    "            \"titanic\",\n",
    "            \"-f\",\n",
    "            filename,\n",
    "            \"-m\",\n",
    "            message\n",
    "        ], \n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(completed_process.stdout)\n",
    "    \n",
    "class DFSimpleImputer(SimpleImputer):\n",
    "    def transform(self, X, y=None):\n",
    "        return pd.DataFrame(super().transform(X), columns=X.columns)\n",
    "\n",
    "class DFOneHotEncoder(OneHotEncoder):\n",
    "    def transform(self, X, y=None):\n",
    "        column_names = X.columns\n",
    "        X_transformed = super().transform(X)\n",
    "        return pd.DataFrame.sparse.from_spmatrix(X_transformed, columns=self.get_feature_names(column_names))\n",
    "\n",
    "def get_preprocessing_pipeline(variant):\n",
    "    if variant == \"default\":\n",
    "        return preprocessing_pipeline_default()\n",
    "    elif variant == \"default_no_dropped_features\":\n",
    "        return preprocessing_pipeline_default_no_dropped_features()\n",
    "    elif variant == \"default_no_dropped_features_log_poly\":\n",
    "        return preprocessing_pipeline_default_no_dropped_features_log_poly()\n",
    "    else:\n",
    "        return preprocessing_pipeline_default()\n",
    "    \n",
    "def get_pipeline(model, preprocessing_variant):\n",
    "    return Pipeline([\n",
    "        (\"preprocessing\", get_preprocessing_pipeline(preprocessing_variant)),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "def compare_models(models, preprocessing_variant=\"default\"):\n",
    "    X_train, y_train = load_train_data()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for model in models:\n",
    "        pipe = get_pipeline(model, preprocessing_variant)\n",
    "        scores = cross_val_score(pipe, X_train, y_train)\n",
    "        \n",
    "        result = {\n",
    "            \"model\": type(model).__name__,\n",
    "            \"accuracy\": \"Accuracy: %0.5f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2),\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline_default():\n",
    "    sex_pipeline = Pipeline([\n",
    "        ('imputer', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    embarked_pipeline = Pipeline([\n",
    "        ('imputer', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    def generate_age_derived_features(X):\n",
    "        has_age = X[\"Age\"].apply(lambda x: 0 if pd.isnull(x) else 1).rename(\"HasAge\")\n",
    "        is_young_child = X[\"Age\"].apply(lambda age: 1 if age < 10 else 0).rename(\"IsYoungChild\")\n",
    "        is_infant = X[\"Age\"].apply(lambda age: 1 if age < 1 else 0).rename(\"IsInfant\")\n",
    "        return pd.concat([X, has_age, is_young_child, is_infant], axis=\"columns\")\n",
    "\n",
    "    def discretize_age(X):\n",
    "        bins = [0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, np.inf]\n",
    "        labels = [\"0+\", \"10+\", \"20+\", \"30+\", \"40+\", \"50+\", \"60+\", \"70+\"]\n",
    "\n",
    "        age_group = pd.cut(X[\"Age\"], bins=bins, labels=labels, include_lowest=True)\n",
    "        age_group = age_group.rename(\"AgeGroup\")\n",
    "\n",
    "        result = pd.concat([X, age_group], axis=\"columns\")    \n",
    "        return result\n",
    "\n",
    "    def drop_age(X):\n",
    "        X = X.drop(\"Age\", axis=\"columns\")\n",
    "        return X\n",
    "\n",
    "    age_pipeline = Pipeline([\n",
    "        (\"age_transformer\", FunctionTransformer(generate_age_derived_features)),\n",
    "        ('impute', DFSimpleImputer(strategy=\"mean\")),\n",
    "        (\"discretize\", FunctionTransformer(discretize_age)),\n",
    "        (\"drop\", FunctionTransformer(drop_age)),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    def attributes_dropper(df):\n",
    "        result_df = df.drop(\"Name\", axis=\"columns\")\n",
    "        result_df = result_df.drop(\"Ticket\", axis=\"columns\")\n",
    "        return result_df\n",
    "\n",
    "    attributes_dropper_transformer = FunctionTransformer(attributes_dropper)\n",
    "\n",
    "    fare_pipeline = Pipeline([\n",
    "        ('impute_missing', DFSimpleImputer(strategy=\"mean\")),\n",
    "        (\"log_transform\", FunctionTransformer(np.log1p)),\n",
    "        ('standard_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    def generate_cabin_derived_features(df):\n",
    "        has_cabin = df[\"Cabin\"].apply(lambda x: 0 if pd.isnull(x) else 1).rename(\"HasCabin\")\n",
    "        cabin_letter = df[\"Cabin\"].apply(lambda string: string[0] if pd.notnull(string) else \"U\")\n",
    "        cabin_letter = cabin_letter.rename(\"CabinLetter\")\n",
    "\n",
    "        return pd.concat([df, has_cabin, cabin_letter], axis=\"columns\")\n",
    "\n",
    "    def drop_cabin(df):\n",
    "        result = df.drop(\"Cabin\", axis=\"columns\")\n",
    "        return result\n",
    "\n",
    "    cabin_pipeline = Pipeline([\n",
    "        (\"generate_derived_features\", FunctionTransformer(generate_cabin_derived_features)),\n",
    "        ('impute', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        (\"drop\", FunctionTransformer(drop_cabin)),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "            (\"sex\", sex_pipeline, [\"Sex\"]),\n",
    "            (\"embarked\", embarked_pipeline, [\"Embarked\"]),\n",
    "            (\"age\", age_pipeline, [\"Age\"]),\n",
    "            (\"attributes_dropper\", attributes_dropper_transformer, [\"Name\", \"Ticket\"]),\n",
    "            (\"fare\", fare_pipeline, [\"Fare\"]),\n",
    "            (\"cabin\", cabin_pipeline, [\"Cabin\"]),\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline_default_no_dropped_features():\n",
    "    sex_pipeline = Pipeline([\n",
    "        ('imputer', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    embarked_pipeline = Pipeline([\n",
    "        ('imputer', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    def generate_age_derived_features(X):\n",
    "        has_age = X[\"Age\"].apply(lambda x: 0 if pd.isnull(x) else 1).rename(\"HasAge\")\n",
    "        is_young_child = X[\"Age\"].apply(lambda age: 1 if age < 10 else 0).rename(\"IsYoungChild\")\n",
    "        is_infant = X[\"Age\"].apply(lambda age: 1 if age < 1 else 0).rename(\"IsInfant\")\n",
    "        return pd.concat([X, has_age, is_young_child, is_infant], axis=\"columns\")\n",
    "\n",
    "    def discretize_age(X):\n",
    "        bins = [0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, np.inf]\n",
    "        labels = [\"0+\", \"10+\", \"20+\", \"30+\", \"40+\", \"50+\", \"60+\", \"70+\"]\n",
    "\n",
    "        age_group = pd.cut(X[\"Age\"], bins=bins, labels=labels, include_lowest=True)\n",
    "        age_group = age_group.rename(\"AgeGroup\")\n",
    "\n",
    "        result = pd.concat([X, age_group], axis=\"columns\")    \n",
    "        return result\n",
    "\n",
    "    age_pipeline = Pipeline([\n",
    "        (\"age_transformer\", FunctionTransformer(generate_age_derived_features)),\n",
    "        ('impute', DFSimpleImputer(strategy=\"mean\")),\n",
    "        (\"discretize\", FunctionTransformer(discretize_age)),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    fare_pipeline = Pipeline([\n",
    "        ('impute_missing', DFSimpleImputer(strategy=\"mean\")),\n",
    "        (\"log_transform\", FunctionTransformer(np.log1p)),\n",
    "        ('standard_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    def generate_cabin_derived_features(df):\n",
    "        has_cabin = df[\"Cabin\"].apply(lambda x: 0 if pd.isnull(x) else 1).rename(\"HasCabin\")\n",
    "        cabin_letter = df[\"Cabin\"].apply(lambda string: string[0] if pd.notnull(string) else \"U\")\n",
    "        cabin_letter = cabin_letter.rename(\"CabinLetter\")\n",
    "\n",
    "        return pd.concat([df, has_cabin, cabin_letter], axis=\"columns\")\n",
    "\n",
    "    cabin_pipeline = Pipeline([\n",
    "        (\"generate_derived_features\", FunctionTransformer(generate_cabin_derived_features)),\n",
    "        ('impute', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    \n",
    "    name_ticket_pipe = Pipeline([\n",
    "        ('imputer', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "            (\"sex\", sex_pipeline, [\"Sex\"]),\n",
    "            (\"embarked\", embarked_pipeline, [\"Embarked\"]),\n",
    "            (\"age\", age_pipeline, [\"Age\"]),\n",
    "            (\"name_ticket_pipe\", name_ticket_pipe, [\"Name\", \"Ticket\"]),\n",
    "            (\"fare\", fare_pipeline, [\"Fare\"]),\n",
    "            (\"cabin\", cabin_pipeline, [\"Cabin\"]),\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline_default_no_dropped_features_log_poly():\n",
    "    sex_pipeline = Pipeline([\n",
    "        ('imputer', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    embarked_pipeline = Pipeline([\n",
    "        ('imputer', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    def generate_age_derived_features(X):\n",
    "        has_age = X[\"Age\"].apply(lambda x: 0 if pd.isnull(x) else 1).rename(\"HasAge\")\n",
    "        is_young_child = X[\"Age\"].apply(lambda age: 1 if age < 10 else 0).rename(\"IsYoungChild\")\n",
    "        is_infant = X[\"Age\"].apply(lambda age: 1 if age < 1 else 0).rename(\"IsInfant\")\n",
    "        return pd.concat([X, has_age, is_young_child, is_infant], axis=\"columns\")\n",
    "\n",
    "    def discretize_age(X):\n",
    "        bins = [0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, np.inf]\n",
    "        labels = [\"0+\", \"10+\", \"20+\", \"30+\", \"40+\", \"50+\", \"60+\", \"70+\"]\n",
    "\n",
    "        age_group = pd.cut(X[\"Age\"], bins=bins, labels=labels, include_lowest=True)\n",
    "        age_group = age_group.rename(\"AgeGroup\")\n",
    "\n",
    "        result = pd.concat([X, age_group], axis=\"columns\")    \n",
    "        return result\n",
    "    \n",
    "    def add_log_poly(X):\n",
    "        X[\"Age_Log\"] = np.log1p(X[\"Age\"])\n",
    "        X[\"Age_Square\"] = np.square(X[\"Age\"])\n",
    "        return X\n",
    "\n",
    "    age_pipeline = Pipeline([\n",
    "        (\"age_transformer\", FunctionTransformer(generate_age_derived_features)),\n",
    "        ('impute', DFSimpleImputer(strategy=\"mean\")),\n",
    "        (\"discretize\", FunctionTransformer(discretize_age)),\n",
    "#         (\"add_log_poly\", FunctionTransformer(add_log_poly)),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    fare_pipeline = Pipeline([\n",
    "        ('impute_missing', DFSimpleImputer(strategy=\"mean\")),\n",
    "        (\"log_transform\", FunctionTransformer(np.log1p)),\n",
    "        ('standard_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    def generate_cabin_derived_features(df):\n",
    "        has_cabin = df[\"Cabin\"].apply(lambda x: 0 if pd.isnull(x) else 1).rename(\"HasCabin\")\n",
    "        cabin_letter = df[\"Cabin\"].apply(lambda string: string[0] if pd.notnull(string) else \"U\")\n",
    "        cabin_letter = cabin_letter.rename(\"CabinLetter\")\n",
    "\n",
    "        return pd.concat([df, has_cabin, cabin_letter], axis=\"columns\")\n",
    "\n",
    "    cabin_pipeline = Pipeline([\n",
    "        (\"generate_derived_features\", FunctionTransformer(generate_cabin_derived_features)),\n",
    "        ('impute', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "    \n",
    "    name_ticket_pipe = Pipeline([\n",
    "        ('imputer', DFSimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        ('one_hot_encoder', DFOneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "            (\"sex\", sex_pipeline, [\"Sex\"]),\n",
    "            (\"embarked\", embarked_pipeline, [\"Embarked\"]),\n",
    "            (\"age\", age_pipeline, [\"Age\"]),\n",
    "            (\"name_ticket_pipe\", name_ticket_pipe, [\"Name\", \"Ticket\"]),\n",
    "            (\"fare\", fare_pipeline, [\"Fare\"]),\n",
    "            (\"cabin\", cabin_pipeline, [\"Cabin\"]),\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "load_train_data: done\n",
      "load_train_data: done\n",
      "\n",
      "===========\n",
      "default\n",
      "\n",
      "LogisticRegression\n",
      "Accuracy: 0.79688 (+/- 0.03)\n",
      "\n",
      "LinearDiscriminantAnalysis\n",
      "Accuracy: 0.80473 (+/- 0.03)\n",
      "\n",
      "KNeighborsClassifier\n",
      "Accuracy: 0.79691 (+/- 0.04)\n",
      "\n",
      "GaussianNB\n",
      "Accuracy: 0.70149 (+/- 0.07)\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Accuracy: 0.81823 (+/- 0.05)\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy: 0.79462 (+/- 0.06)\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy: 0.81038 (+/- 0.07)\n",
      "\n",
      "SVC\n",
      "Accuracy: 0.82716 (+/- 0.03)\n",
      "\n",
      "LinearSVC\n",
      "Accuracy: 0.80024 (+/- 0.04)\n",
      "\n",
      "\n",
      "===========\n",
      "default_no_dropped_features\n",
      "\n",
      "LogisticRegression\n",
      "Accuracy: 0.82267 (+/- 0.03)\n",
      "\n",
      "LinearDiscriminantAnalysis\n",
      "Accuracy: 0.74302 (+/- 0.06)\n",
      "\n",
      "KNeighborsClassifier\n",
      "Accuracy: 0.79015 (+/- 0.05)\n",
      "\n",
      "GaussianNB\n",
      "Accuracy: 0.48704 (+/- 0.05)\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Accuracy: 0.81933 (+/- 0.06)\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy: 0.82719 (+/- 0.06)\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy: 0.71833 (+/- 0.04)\n",
      "\n",
      "SVC\n",
      "Accuracy: 0.82155 (+/- 0.03)\n",
      "\n",
      "LinearSVC\n",
      "Accuracy: 0.83614 (+/- 0.01)\n",
      "\n",
      "\n",
      "===========\n",
      "default_no_dropped_features_log_poly\n",
      "\n",
      "LogisticRegression\n",
      "Accuracy: 0.82267 (+/- 0.03)\n",
      "\n",
      "LinearDiscriminantAnalysis\n",
      "Accuracy: 0.74302 (+/- 0.06)\n",
      "\n",
      "KNeighborsClassifier\n",
      "Accuracy: 0.79015 (+/- 0.05)\n",
      "\n",
      "GaussianNB\n",
      "Accuracy: 0.48704 (+/- 0.05)\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Accuracy: 0.81480 (+/- 0.05)\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy: 0.82719 (+/- 0.06)\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy: 0.71833 (+/- 0.04)\n",
      "\n",
      "SVC\n",
      "Accuracy: 0.82155 (+/- 0.03)\n",
      "\n",
      "LinearSVC\n",
      "Accuracy: 0.83614 (+/- 0.01)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_models():\n",
    "    return [\n",
    "        LogisticRegression(),\n",
    "        LinearDiscriminantAnalysis(),\n",
    "        KNeighborsClassifier(),\n",
    "        GaussianNB(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1),\n",
    "        SVC(),\n",
    "        LinearSVC(random_state=42, max_iter=10000),\n",
    "    ]\n",
    "\n",
    "def get_preprocessing_pipelines():\n",
    "    return [\n",
    "        \"default\",\n",
    "        \"default_no_dropped_features\",\n",
    "        \"default_no_dropped_features_log_poly\",\n",
    "    ]\n",
    "\n",
    "results_per_pipeline = []\n",
    "\n",
    "for pipe in get_preprocessing_pipelines():\n",
    "    result = compare_models(get_models(), preprocessing_variant=pipe)\n",
    "    results_per_pipeline.append({pipe: result})\n",
    "    \n",
    "for results in results_per_pipeline:\n",
    "    key = list(results.keys())[0]\n",
    "    model_results = results[key]\n",
    "    \n",
    "    print(\"\\n===========\")\n",
    "    print(f\"{key}\\n\")\n",
    "\n",
    "    for result in model_results:\n",
    "        print(result[\"model\"])\n",
    "        print(result[\"accuracy\"])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'LogisticRegression', 'accuracy': 'Accuracy: 0.82267 (+/- 0.03)'},\n",
       " {'model': 'LinearDiscriminantAnalysis',\n",
       "  'accuracy': 'Accuracy: 0.74302 (+/- 0.06)'},\n",
       " {'model': 'KNeighborsClassifier', 'accuracy': 'Accuracy: 0.79015 (+/- 0.05)'},\n",
       " {'model': 'GaussianNB', 'accuracy': 'Accuracy: 0.48704 (+/- 0.05)'},\n",
       " {'model': 'DecisionTreeClassifier',\n",
       "  'accuracy': 'Accuracy: 0.81144 (+/- 0.04)'},\n",
       " {'model': 'RandomForestClassifier',\n",
       "  'accuracy': 'Accuracy: 0.82719 (+/- 0.06)'},\n",
       " {'model': 'SVC', 'accuracy': 'Accuracy: 0.82155 (+/- 0.03)'},\n",
       " {'model': 'LinearSVC', 'accuracy': 'Accuracy: 0.83614 (+/- 0.01)'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(get_models(), preprocessing_variant=\"default_no_dropped_features_log_poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_train_data: done\n",
      "Accuracy: 0.81038 (+/- 0.07)\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "pipe = get_pipeline(model, \"default\")\n",
    "\n",
    "X_train, y_train = load_train_data()\n",
    "X_test = load_x_test()\n",
    "\n",
    "scores = cross_val_score(pipe, X_train, y_train)\n",
    "print(\"Accuracy: %0.5f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "predictions = pipe.predict(X_test)\n",
    "output = pd.DataFrame({'PassengerId': X_test.index, 'Survived': predictions})\n",
    "output.to_csv('submissions/06-random-forest.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
